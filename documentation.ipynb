{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb6326d",
   "metadata": {},
   "source": [
    "# CSUSB Study Abroad Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f154a",
   "metadata": {},
   "source": [
    "## **1. Introduction**\n",
    "The CSUSB Study Abroad Chatbot is a Streamlit-based chatbot that provides information related to study abroad opportunities at California State University, San Bernardino (CSUSB). This chatbot was developed by Team 2 for CSE 6550: Software Engineering Concepts.\n",
    "\n",
    "In this notebook, we will demonstrate how the chatbot uses retrieval-augmented generation (RAG) to answer questions using study abroad resources as the primary data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2012fb3d",
   "metadata": {},
   "source": [
    "### Features:\n",
    "- A **cooldown system** to limit excessive queries and prevent overloading the server.\n",
    "- **Message persistence** using `st.session_state` to retain chat history.\n",
    "- A **basic interactive UI** that allows users to input questions and receive responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe6881",
   "metadata": {},
   "source": [
    "## **2. Installation Requirements**\n",
    "To run this chatbot, install Streamlit:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ba0b3",
   "metadata": {},
   "source": [
    "Other built-in Python modules used:\n",
    "- `time`: Used for handling **cooldown timers** and response tracking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8835338",
   "metadata": {},
   "source": [
    "## **3. Code Explanation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6051f",
   "metadata": {},
   "source": [
    "### **3.1 Importing Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47240f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st  # Streamlit for web-based chatbot UI\n",
    "import time  # Time module for cooldown system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f575f6",
   "metadata": {},
   "source": [
    "- `streamlit` is used to create the **interactive chatbot UI**.\n",
    "- `time` is used to **track message cooldown periods** and measure response times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3e0d6",
   "metadata": {},
   "source": [
    "### **3.2 Cooldown System Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "COOLDOWN_CHECK_PERIOD: float = 60.  # Time window (in seconds) for checking message frequency\n",
    "MAX_MESSAGES_BEFORE_COOLDOWN: int = 10  # Maximum messages allowed before cooldown activates\n",
    "COOLDOWN_DURATION: float = 180.  # Cooldown period in seconds (3 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cdd208",
   "metadata": {},
   "source": [
    "- Users can send **10 messages per minute** before hitting a cooldown.\n",
    "- Once the **limit is exceeded**, users must **wait 3 minutes** before sending more messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69060ff0",
   "metadata": {},
   "source": [
    "### **3.3 Cooldown Management Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe924067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canAnswer() -> bool:\n",
    "    currentTimestamp = time.monotonic()  # Get the current timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd07e71",
   "metadata": {},
   "source": [
    "- `time.monotonic()` ensures that time **only moves forward**, preventing issues with time tracking.\n",
    "- This function **determines if the chatbot can answer** based on the cooldown status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c74b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.session_state[\"cooldownBeginTimestamp\"] is not None:  # Check if cooldown is active\n",
    "        if currentTimestamp - st.session_state[\"cooldownBeginTimestamp\"] >= COOLDOWN_DURATION:\n",
    "            st.session_state[\"cooldownBeginTimestamp\"] = None  # Reset cooldown if time has passed\n",
    "            return True  # Allow user to send a message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f4423",
   "metadata": {},
   "source": [
    "- If **cooldown is active**, it checks whether **enough time has passed**.\n",
    "- If the cooldown period **has expired**, the chatbot resets the cooldown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "else:\n",
    "        st.session_state[\"messageTimes\"] = st.session_state[\"messageTimes\"][-MAX_MESSAGES_BEFORE_COOLDOWN:]\n",
    "        st.session_state[\"messageTimes\"].append(currentTimestamp)  # Track message timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d22a7",
   "metadata": {},
   "source": [
    "- Stores only the last **10 message timestamps** (removes old ones to manage memory).\n",
    "- Ensures that **only recent messages are considered** for cooldown checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    " if len(st.session_state[\"messageTimes\"]) <= MAX_MESSAGES_BEFORE_COOLDOWN or            st.session_state[\"messageTimes\"][-1] - st.session_state[\"messageTimes\"][-MAX_MESSAGES_BEFORE_COOLDOWN - 1] >= COOLDOWN_CHECK_PERIOD:\n",
    "            return True  # Allow message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31409b15",
   "metadata": {},
   "source": [
    "- Checks if the user has sent fewer than **10 messages per minute**.\n",
    "- If the limit is not reached, **they can continue chatting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "else:\n",
    "            st.session_state[\"cooldownBeginTimestamp\"] = currentTimestamp  # Start cooldown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb07ed",
   "metadata": {},
   "source": [
    "- **Activates cooldown mode** if the limit is reached.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa69ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "remainingTime = COOLDOWN_DURATION + st.session_state[\"cooldownBeginTimestamp\"] - currentTimestamp\n",
    "    st.write(f\"ERROR: You've reached the limit of {MAX_MESSAGES_BEFORE_COOLDOWN} messages. Please try again in {int(remainingTime//60)} minutes.\")\n",
    "    return False  # Prevent further messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4f14c",
   "metadata": {},
   "source": [
    "\n",
    "- **Calculates the remaining cooldown time** and **displays an error message** if the user must wait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e44c80",
   "metadata": {},
   "source": [
    "### **3.4 Setting Up Streamlit Chat UI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.html(\"<h1 style='text-align:center; font-size:48px'>CSUSB Travel Abroad Chatbot</h1>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781850e1",
   "metadata": {},
   "source": [
    "\n",
    "- Displays the **chatbot title** in large, centered text for better UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a18cd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **3.5 Initializing Session Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"messages\" not in st.session_state or not isinstance(st.session_state[\"messages\"], list):\n",
    "    st.session_state[\"messages\"] = []  # Store chat history\n",
    "if \"cooldownBeginTimestamp\" not in st.session_state:\n",
    "    st.session_state[\"cooldownBeginTimestamp\"] = None  # Track cooldown start time\n",
    "if \"messageTimes\" not in st.session_state:\n",
    "    st.session_state[\"messageTimes\"] = []  # Store message timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7eb4da",
   "metadata": {},
   "source": [
    "- **Ensures session state variables are initialized**:\n",
    "  - `messages`: Stores **previous chat messages**.\n",
    "  - `cooldownBeginTimestamp`: Keeps **track of cooldown activation**.\n",
    "  - `messageTimes`: Stores **timestamps of sent messages**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f3fbf",
   "metadata": {},
   "source": [
    "### **3.6 Displaying Chat History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e67d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in st.session_state[\"messages\"]:  # Loop through stored messages\n",
    "    with st.chat_message(message[\"role\"]):  # Display message\n",
    "        st.markdown(message[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1bc4a5",
   "metadata": {},
   "source": [
    "- **Loops through stored messages** and displays them in the chat window.\n",
    "- **Keeps past conversations visible**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0489f4de",
   "metadata": {},
   "source": [
    "### **3.7 Handling User Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d03604",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = st.chat_input(\"What is your question?\")  # Capture user input\n",
    "if prompt and canAnswer():  # Check cooldown before processing message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cce998",
   "metadata": {},
   "source": [
    "- `st.chat_input()` **creates an input box** for the user.\n",
    "- Calls `canAnswer()` **to check if the user is allowed to send a message**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77032802",
   "metadata": {},
   "outputs": [],
   "source": [
    " st.chat_message(\"human\").markdown(prompt)  # Display user input\n",
    "    st.session_state[\"messages\"].append({\"role\": \"human\", \"content\": prompt})  # Save message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de816b7",
   "metadata": {},
   "source": [
    "- **Displays the user’s message** in the chat window.\n",
    "- **Saves the message** to maintain chat history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ef5ac",
   "metadata": {},
   "source": [
    "### **3.8 Processing AI Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c997e0",
   "metadata": {},
   "outputs": [],
   "source": [
    " responseStartTime = time.monotonic()  # Start response timer\n",
    "    with st.chat_message(\"ai\"):\n",
    "        response = \"[LLM response here]\"  # Placeholder for AI-generated text\n",
    "        responseEndTime = time.monotonic()  # End response timer\n",
    "        st.markdown(response)  # Display AI response\n",
    "        st.session_state[\"messages\"].append({\"role\": \"ai\", \"content\": response})  # Save response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d7865",
   "metadata": {},
   "source": [
    "- **Tracks response time** for AI-generated messages.\n",
    "- Uses a **placeholder AI response** (`\"[LLM response here]\"`) that can be replaced with an **LLM-generated response**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if responseEndTime:  # Display response time for tracking\n",
    "        st.write(f\"*(Last response took {responseEndTime - responseStartTime:.4f} seconds)*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971bea59",
   "metadata": {},
   "source": [
    "- **Displays the response time** to track chatbot efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ea368",
   "metadata": {},
   "source": [
    "\n",
    "## **4. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ef02d",
   "metadata": {},
   "source": [
    "\n",
    "✅ **Prevents message spam** with a cooldown system.  \n",
    "✅ **Saves chat history** for a seamless conversation flow.  \n",
    "✅ **Provides AI-generated responses** (can be expanded with OpenAI).  \n",
    "✅ **Tracks response time** for performance analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "from typing import Literal, TypeAlias\n",
    "\n",
    "AnswerTypes: TypeAlias = Literal[\"yes\", \"no\", \"unanswerable\"]\n",
    "\n",
    "COOLDOWN_CHECK_PERIOD = 60.0  # Time window in seconds to count messages for cooldown\n",
    "MAX_MESSAGES_BEFORE_COOLDOWN = 10  # Maximum allowed messages within the check period before cooldown\n",
    "COOLDOWN_DURATION = 180.0  # Duration (in seconds) of the cooldown period once the limit is reached\n",
    "MAX_RESPONSE_TIME = 3.0  # Maximum acceptable response time in seconds before highlighting slow responses\n",
    "ANSWER_TYPE_MAX_CHARACTERS_TO_CHECK = 30\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are Llama 3, an expert assistant for the Study Abroad program of California State University, San Bernardino (CSUSB).\n",
    "Your purpose is to help students with all questions related to studying abroad. You provide detailed, accurate, and helpful information about scholarships, visa processes, university applications, living abroad, cultural adaptation, and academic opportunities worldwide.\n",
    "Rules & Restrictions:\n",
    "- **Stay on Topic:** Only respond to questions related to studying abroad, scholarships, university admissions, visas, or life as an international student. If a question is unrelated (e.g. politics or unrelated personal advice), politely guide the user back to study abroad topics.\n",
    "- **No Negative Responses:** While you must remain truthful at all times, also avoid negative opinions, discouragement, or any response that may deter students from studying abroad.\n",
    "- **Encourage and Inform:** Provide factual, detailed, and encouraging responses to all study abroad inquiries.\n",
    "- **No Controversial Discussions:** Do not engage in topics outside of studying abroad, including politics, religion, or personal debates.\n",
    "- You MUST begin every response with either the phrase \"Yes\", \"No\", or \"I cannot answer that\".\n",
    "\"\"\"\n",
    "\n",
    "ANSWERABLE_QUESTIONS: dict[str, AnswerTypes] = {\n",
    "    \"does csusb offer study abroad programs?\": \"yes\",\n",
    "    \"can i apply for a study abroad program at csusb?\": \"yes\",\n",
    "    \"is toronto a good place for students to live while studying abroad?\": \"yes\",\n",
    "    \"do i need a visa to study at the university of seoul?\": \"yes\",\n",
    "    \"can i study in south korea or taiwan if I only know english?\": \"yes\"\n",
    "}\n",
    "CORRECT_ANSWER_KEYWORDS: tuple[str] = (\"yes\", \"indeed\", \"correct\", \"right\")\n",
    "UNANSWERABLE_ANSWER_KEYWORDS: tuple[str] = (\"i cannot answer\", \"i cannot help with\", \"i do not know\")\n",
    "\n",
    "api_key = \"\"\n",
    "cooldownBeginTimestamp: float | None = None\n",
    "messages = []\n",
    "messageTimes: list = []\n",
    "eval_data = {\"y_true\": [], \"y_pred\": []}\n",
    "\n",
    "def canAnswer() -> bool:\n",
    "    global cooldownBeginTimestamp, messageTimes\n",
    "    \"\"\"Check if user can send a new message based on cooldown logic.\"\"\"\n",
    "    currentTimestamp = time.monotonic()  # Get the current time in seconds\n",
    "    if cooldownBeginTimestamp is not None:\n",
    "        if currentTimestamp - cooldownBeginTimestamp >= COOLDOWN_DURATION:\n",
    "            cooldownBeginTimestamp = None\n",
    "            return True\n",
    "    else:\n",
    "        messageTimes = messageTimes[-MAX_MESSAGES_BEFORE_COOLDOWN:]\n",
    "        messageTimes.append(currentTimestamp)\n",
    "        if (\n",
    "            len(messageTimes) <= MAX_MESSAGES_BEFORE_COOLDOWN\n",
    "            or messageTimes[-1] - messageTimes[-MAX_MESSAGES_BEFORE_COOLDOWN - 1] >= COOLDOWN_CHECK_PERIOD\n",
    "        ):\n",
    "            return True\n",
    "        else:\n",
    "            cooldownBeginTimestamp = currentTimestamp\n",
    "\n",
    "    cooldownMinutes = int(COOLDOWN_CHECK_PERIOD // 60)\n",
    "    cooldownSeconds = int(COOLDOWN_CHECK_PERIOD) % 60\n",
    "    remainingTime = COOLDOWN_DURATION + cooldownBeginTimestamp - currentTimestamp\n",
    "    remainingMinutes = int(remainingTime // 60)\n",
    "    remainingSeconds = int(remainingTime) % 60\n",
    "    print(\n",
    "        f\"ERROR: You've reached the limit of {MAX_MESSAGES_BEFORE_COOLDOWN} questions per \"\n",
    "        f\"{cooldownMinutes} minute{'s' if cooldownMinutes != 1 else ''} {cooldownSeconds} second{'s' if cooldownSeconds != 1 else ''}. \"\n",
    "        f\"Please try again in {remainingMinutes} minute{'s' if remainingMinutes != 1 else ''} \"\n",
    "        f\"{remainingSeconds} second{'s' if remainingSeconds != 1 else ''}.\"\n",
    "    )\n",
    "    return False\n",
    "\n",
    "def apiBox():\n",
    "    global api_key\n",
    "    while True:\n",
    "        api_key = input(\"Please enter your Groq API key: \")\n",
    "        if api_key: break\n",
    "        print(\"Invalid key provided. \", end=\"\")\n",
    "\n",
    "def updateEvalData(question: str, givenAnswer: str) -> None:\n",
    "    global eval_data\n",
    "    correctAnswerType = ANSWERABLE_QUESTIONS[question.strip().lower()].lower() if question.strip().lower() in ANSWERABLE_QUESTIONS else \"unanswerable\"\n",
    "    if any(keyword.lower() in givenAnswer[:ANSWER_TYPE_MAX_CHARACTERS_TO_CHECK].lower() for keyword in CORRECT_ANSWER_KEYWORDS): givenAnswerType = \"yes\"\n",
    "    elif any(keyword.lower() in givenAnswer[:ANSWER_TYPE_MAX_CHARACTERS_TO_CHECK].lower() for keyword in UNANSWERABLE_ANSWER_KEYWORDS): givenAnswerType = \"unanswerable\"\n",
    "    else: givenAnswerType = \"no\"\n",
    "\n",
    "    eval_data[\"y_true\"].append(correctAnswerType != \"unanswerable\")\n",
    "    eval_data[\"y_pred\"].append(givenAnswerType != \"unanswerable\" and (correctAnswerType == \"unanswerable\" or givenAnswerType == correctAnswerType))\n",
    "\n",
    "def render_confusion_matrix():\n",
    "    global eval_data\n",
    "    y_true = eval_data[\"y_true\"]\n",
    "    y_pred = eval_data[\"y_pred\"]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
    "    TP = cm[0, 0]\n",
    "    FN = cm[0, 1]\n",
    "    FP = cm[1, 0]\n",
    "    TN = cm[1, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred) if y_true or y_pred else 0\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    sensitivity = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    specificity = TN / (TN + FP) if TN + FP else 0\n",
    "\n",
    "    print(f\"\"\"\n",
    "        =================\n",
    "             +     -\n",
    "          ------------- \n",
    "        + | {TP:>3} | {FN:>3} |\n",
    "        - | {FP:>3} | {TN:>3} |\n",
    "          -------------\n",
    "        Accuracy: {accuracy:.2f}\n",
    "        Precision: {precision:.2f}\n",
    "        Sensitivity: {sensitivity:.2f}\n",
    "        F1 score: {f1:.2f}\n",
    "        Specificity: {specificity:.2f}\n",
    "        =================\n",
    "    \"\"\")\n",
    "\n",
    "def mainPage():\n",
    "    global api_key, cooldownBeginTimestamp, messages, messageTimes, eval_data\n",
    "    apiBox()\n",
    "\n",
    "    ai = ChatGroq(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        api_key=api_key,  # Pass the API key explicitly.\n",
    "    )\n",
    "\n",
    "    responseStartTime, responseEndTime = 0.0, 0.0\n",
    "    \n",
    "    while True:\n",
    "        while True:\n",
    "            prompt = input(\"What is your question? \")\n",
    "            if prompt: break\n",
    "        if not canAnswer(): continue\n",
    "        messages.append({\"role\": \"human\", \"content\": prompt})\n",
    "        sentMessages = [(\"system\", SYSTEM_PROMPT)] + [(m[\"role\"], m[\"content\"]) for m in messages]\n",
    "        responseStartTime = time.monotonic()\n",
    "        response = ai.invoke(sentMessages)\n",
    "        responseEndTime = time.monotonic()\n",
    "        print(\"Llama 3: \", response.content)\n",
    "        messages.append({\"role\": \"ai\", \"content\": response.content})\n",
    "        \n",
    "        if responseEndTime:\n",
    "            responseTime = responseEndTime - responseStartTime\n",
    "            time_label = f\"{responseTime:.4f} seconds\"\n",
    "            print(f\"(Last response took {time_label})\")\n",
    "        \n",
    "        updateEvalData(prompt, response.content)\n",
    "        render_confusion_matrix()\n",
    "\n",
    "def main():\n",
    "    mainPage()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
